{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49903f6f-ec34-4131-8d55-0913de537e17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a57d8037-ae67-4efb-b426-5e9f8fd55248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Jul 19 01:01:12 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.35.05              Driver Version: 560.35.05      CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3090        On  |   00000000:81:00.0  On |                  N/A |\n",
      "|  0%   41C    P8             31W /  370W |   14646MiB /  24576MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A    586370      C   ....conda/envs/kg_pipeline/bin/python3      14636MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd9c637-9735-49d1-9ae4-120b14dde7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kill 586370                                                                                                                                                                                                                                                                                                                                                                                                                                                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e34dcc6e-95b4-423a-93d0-d3ee6fc6dc2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/upb/users/b/balram/profiles/unix/cs/.conda/envs/kg_pipeline/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "import json\n",
    "import jsonlines\n",
    "import re\n",
    "import time\n",
    "\n",
    "torch.backends.cudnn.benchmark = True  # speedup\n",
    "\n",
    "def setup_model(model_id=\"mistralai/Mistral-7B-Instruct-v0.3\"):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_id,\n",
    "        device_map=\"auto\",\n",
    "        torch_dtype=torch.float16,\n",
    "    )\n",
    "\n",
    "    model.config.use_cache = False  # optional; can toggle True if preferred\n",
    "\n",
    "    pipe = pipeline(\n",
    "        \"text-generation\",\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        device_map=\"auto\"\n",
    "    )\n",
    "    return pipe, tokenizer\n",
    "\n",
    "def load_prompts(filepath):\n",
    "    with jsonlines.open(filepath) as reader:\n",
    "        return list(reader)\n",
    "\n",
    "def generate_text(generator, tokenizer, prompts, max_new_tokens=512):\n",
    "    input_lens = [tokenizer(p, return_tensors=\"pt\")['input_ids'].shape[1] for p in prompts]\n",
    "    max_tokens_batch = [min(2 * l, max_new_tokens) for l in input_lens]\n",
    "    max_new_tokens = max(max_tokens_batch) if max_tokens_batch else max_new_tokens\n",
    "\n",
    "    outputs = generator(\n",
    "        prompts,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        truncation=True,\n",
    "        num_return_sequences=2,\n",
    "        temperature=0.2,\n",
    "        top_p=0.9,\n",
    "        do_sample=True,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "    # Flatten list of lists if pipeline returns nested list\n",
    "    if isinstance(outputs[0], list):\n",
    "        outputs = [item for sublist in outputs for item in sublist]\n",
    "    \n",
    "    return outputs\n",
    "\n",
    "\n",
    "def extract_test_outputs(response):\n",
    "    outputs = []\n",
    "    if response and len(response) > 0:\n",
    "        for res in response:\n",
    "            generated_text = res.get('generated_text', '')\n",
    "            match = re.search(r'Test Output:\\s*(.*?)(?=\\n\\s*#|$)', generated_text, re.DOTALL)\n",
    "            if match:\n",
    "                outputs.append(match.group(1).strip())\n",
    "    return outputs if outputs else ['Output not found']\n",
    "\n",
    "def parse_model_output(model_output):\n",
    "    triples = []\n",
    "    lines = [line.strip() for line in model_output.strip().split('\\n') if line.strip()]\n",
    "    pattern = re.compile(r'(.+?)\\s*\\(([^,]+),\\s*([^)]+)\\)')\n",
    "    for line in lines:\n",
    "        for match in pattern.findall(line):\n",
    "            relation, subject, obj = match\n",
    "            triples.append({\n",
    "                \"sub\": subject.strip(),\n",
    "                \"rel\": relation.strip(),\n",
    "                \"obj\": obj.strip()\n",
    "            })\n",
    "    return triples\n",
    "\n",
    "def save_triples(processed_data, output_filepath):\n",
    "    with open(output_filepath, 'w', encoding='utf-8') as outfile:\n",
    "        for entry in processed_data:\n",
    "            json.dump({\"id\": entry[\"id\"], \"triples\": entry[\"triples\"]}, outfile, ensure_ascii=False)\n",
    "            outfile.write(\"\\n\")\n",
    "\n",
    "def main(jsonl_path, output_path, generator, tokenizer, num_prompts=548, batch_size=16):\n",
    "    prompts = load_prompts(jsonl_path)\n",
    "    results = []\n",
    "\n",
    "    for i in range(0, min(num_prompts, len(prompts)), batch_size):\n",
    "        batch = prompts[i:i + batch_size]\n",
    "        batch_ids = [item['id'] for item in batch]\n",
    "        batch_prompts = [item['prompt'] for item in batch]\n",
    "\n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            responses = generate_text(generator, tokenizer, batch_prompts)\n",
    "            elapsed = time.time() - start_time\n",
    "            print(f\"Batch {i}-{i+len(batch)-1} inference time: {elapsed:.2f} seconds\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error in batch {i}-{i+batch_size}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # responses length = batch_size * num_return_sequences (2)\n",
    "        # group responses per prompt (2 each)\n",
    "        for idx in range(len(batch)):\n",
    "            # Each prompt has 2 responses: response at idx*2 and idx*2 + 1\n",
    "            prompt_responses = responses[2*idx:2*idx+2]\n",
    "\n",
    "            test_outputs = extract_test_outputs(prompt_responses)\n",
    "\n",
    "            all_triples = []\n",
    "            seen = set()\n",
    "            for test_output in test_outputs:\n",
    "                triples = parse_model_output(test_output)\n",
    "                for triple in triples:\n",
    "                    triple_key = (triple[\"sub\"], triple[\"rel\"], triple[\"obj\"])\n",
    "                    if triple_key not in seen:\n",
    "                        seen.add(triple_key)\n",
    "                        all_triples.append(triple)\n",
    "\n",
    "            print(f\"[{i + idx + 1}/{num_prompts}] ID: {batch_ids[idx]} → Unique triples extracted: {len(all_triples)}\")\n",
    "\n",
    "            results.append({\n",
    "                \"id\": batch_ids[idx],\n",
    "                \"triples\": all_triples\n",
    "            })\n",
    "            \n",
    "    save_triples(results, output_path)\n",
    "    print(f\"\\n✅ All {len(results)} prompts processed. Results saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2865d0c6-41a0-4bd6-abf7-71821a840b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:03<00:00,  1.02s/it]\n",
      "Device set to use cuda:0\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0-3 inference time: 54.95 seconds\n",
      "[1/1500] ID: ont_5_military_test_1 → Unique triples extracted: 1\n",
      "[2/1500] ID: ont_5_military_test_2 → Unique triples extracted: 2\n",
      "[3/1500] ID: ont_5_military_test_3 → Unique triples extracted: 3\n",
      "[4/1500] ID: ont_5_military_test_4 → Unique triples extracted: 4\n",
      "Batch 4-7 inference time: 93.58 seconds\n",
      "[5/1500] ID: ont_5_military_test_5 → Unique triples extracted: 1\n",
      "[6/1500] ID: ont_5_military_test_6 → Unique triples extracted: 2\n",
      "[7/1500] ID: ont_5_military_test_7 → Unique triples extracted: 1\n",
      "[8/1500] ID: ont_5_military_test_8 → Unique triples extracted: 0\n",
      "Batch 8-11 inference time: 66.84 seconds\n",
      "[9/1500] ID: ont_5_military_test_9 → Unique triples extracted: 8\n",
      "[10/1500] ID: ont_5_military_test_10 → Unique triples extracted: 2\n",
      "[11/1500] ID: ont_5_military_test_11 → Unique triples extracted: 1\n",
      "[12/1500] ID: ont_5_military_test_12 → Unique triples extracted: 1\n",
      "Batch 12-15 inference time: 70.86 seconds\n",
      "[13/1500] ID: ont_5_military_test_13 → Unique triples extracted: 1\n",
      "[14/1500] ID: ont_5_military_test_14 → Unique triples extracted: 2\n",
      "[15/1500] ID: ont_5_military_test_15 → Unique triples extracted: 1\n",
      "[16/1500] ID: ont_5_military_test_16 → Unique triples extracted: 1\n",
      "Batch 16-19 inference time: 57.06 seconds\n",
      "[17/1500] ID: ont_5_military_test_17 → Unique triples extracted: 5\n",
      "[18/1500] ID: ont_5_military_test_18 → Unique triples extracted: 1\n",
      "[19/1500] ID: ont_5_military_test_19 → Unique triples extracted: 2\n",
      "[20/1500] ID: ont_5_military_test_20 → Unique triples extracted: 7\n",
      "Batch 20-23 inference time: 86.95 seconds\n",
      "[21/1500] ID: ont_5_military_test_21 → Unique triples extracted: 1\n",
      "[22/1500] ID: ont_5_military_test_22 → Unique triples extracted: 1\n",
      "[23/1500] ID: ont_5_military_test_23 → Unique triples extracted: 1\n",
      "[24/1500] ID: ont_5_military_test_24 → Unique triples extracted: 1\n",
      "Batch 24-27 inference time: 31.54 seconds\n",
      "[25/1500] ID: ont_5_military_test_25 → Unique triples extracted: 3\n",
      "[26/1500] ID: ont_5_military_test_26 → Unique triples extracted: 4\n",
      "[27/1500] ID: ont_5_military_test_27 → Unique triples extracted: 2\n",
      "[28/1500] ID: ont_5_military_test_28 → Unique triples extracted: 2\n",
      "Batch 28-31 inference time: 75.35 seconds\n",
      "[29/1500] ID: ont_5_military_test_29 → Unique triples extracted: 1\n",
      "[30/1500] ID: ont_5_military_test_30 → Unique triples extracted: 1\n",
      "[31/1500] ID: ont_5_military_test_31 → Unique triples extracted: 1\n",
      "[32/1500] ID: ont_5_military_test_32 → Unique triples extracted: 7\n",
      "Batch 32-35 inference time: 56.97 seconds\n",
      "[33/1500] ID: ont_5_military_test_33 → Unique triples extracted: 1\n",
      "[34/1500] ID: ont_5_military_test_34 → Unique triples extracted: 15\n",
      "[35/1500] ID: ont_5_military_test_35 → Unique triples extracted: 1\n",
      "[36/1500] ID: ont_5_military_test_36 → Unique triples extracted: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 36-39 inference time: 74.89 seconds\n",
      "[37/1500] ID: ont_5_military_test_37 → Unique triples extracted: 4\n",
      "[38/1500] ID: ont_5_military_test_38 → Unique triples extracted: 6\n",
      "[39/1500] ID: ont_5_military_test_39 → Unique triples extracted: 2\n",
      "[40/1500] ID: ont_5_military_test_40 → Unique triples extracted: 1\n",
      "Batch 40-43 inference time: 57.34 seconds\n",
      "[41/1500] ID: ont_5_military_test_41 → Unique triples extracted: 6\n",
      "[42/1500] ID: ont_5_military_test_42 → Unique triples extracted: 1\n",
      "[43/1500] ID: ont_5_military_test_43 → Unique triples extracted: 1\n",
      "[44/1500] ID: ont_5_military_test_44 → Unique triples extracted: 9\n",
      "Batch 44-47 inference time: 52.87 seconds\n",
      "[45/1500] ID: ont_5_military_test_45 → Unique triples extracted: 1\n",
      "[46/1500] ID: ont_5_military_test_46 → Unique triples extracted: 1\n",
      "[47/1500] ID: ont_5_military_test_47 → Unique triples extracted: 3\n",
      "[48/1500] ID: ont_5_military_test_48 → Unique triples extracted: 1\n",
      "Batch 48-51 inference time: 93.56 seconds\n",
      "[49/1500] ID: ont_5_military_test_49 → Unique triples extracted: 1\n",
      "[50/1500] ID: ont_5_military_test_50 → Unique triples extracted: 1\n",
      "[51/1500] ID: ont_5_military_test_51 → Unique triples extracted: 8\n",
      "[52/1500] ID: ont_5_military_test_52 → Unique triples extracted: 1\n",
      "Batch 52-55 inference time: 92.64 seconds\n",
      "[53/1500] ID: ont_5_military_test_53 → Unique triples extracted: 1\n",
      "[54/1500] ID: ont_5_military_test_54 → Unique triples extracted: 1\n",
      "[55/1500] ID: ont_5_military_test_55 → Unique triples extracted: 1\n",
      "[56/1500] ID: ont_5_military_test_56 → Unique triples extracted: 1\n",
      "Batch 56-59 inference time: 51.61 seconds\n",
      "[57/1500] ID: ont_5_military_test_57 → Unique triples extracted: 2\n",
      "[58/1500] ID: ont_5_military_test_58 → Unique triples extracted: 4\n",
      "[59/1500] ID: ont_5_military_test_59 → Unique triples extracted: 1\n",
      "[60/1500] ID: ont_5_military_test_60 → Unique triples extracted: 1\n",
      "Batch 60-63 inference time: 74.83 seconds\n",
      "[61/1500] ID: ont_5_military_test_61 → Unique triples extracted: 1\n",
      "[62/1500] ID: ont_5_military_test_62 → Unique triples extracted: 1\n",
      "[63/1500] ID: ont_5_military_test_63 → Unique triples extracted: 6\n",
      "[64/1500] ID: ont_5_military_test_64 → Unique triples extracted: 1\n",
      "Batch 64-67 inference time: 21.80 seconds\n",
      "[65/1500] ID: ont_5_military_test_65 → Unique triples extracted: 1\n",
      "[66/1500] ID: ont_5_military_test_66 → Unique triples extracted: 3\n",
      "[67/1500] ID: ont_5_military_test_67 → Unique triples extracted: 2\n",
      "[68/1500] ID: ont_5_military_test_68 → Unique triples extracted: 6\n",
      "Batch 68-71 inference time: 10.32 seconds\n",
      "[69/1500] ID: ont_5_military_test_69 → Unique triples extracted: 3\n",
      "[70/1500] ID: ont_5_military_test_70 → Unique triples extracted: 3\n",
      "[71/1500] ID: ont_5_military_test_71 → Unique triples extracted: 1\n",
      "[72/1500] ID: ont_5_military_test_72 → Unique triples extracted: 9\n",
      "Batch 72-75 inference time: 25.71 seconds\n",
      "[73/1500] ID: ont_5_military_test_73 → Unique triples extracted: 2\n",
      "[74/1500] ID: ont_5_military_test_74 → Unique triples extracted: 1\n",
      "[75/1500] ID: ont_5_military_test_75 → Unique triples extracted: 5\n",
      "[76/1500] ID: ont_5_military_test_76 → Unique triples extracted: 8\n",
      "Batch 76-79 inference time: 70.63 seconds\n",
      "[77/1500] ID: ont_5_military_test_77 → Unique triples extracted: 1\n",
      "[78/1500] ID: ont_5_military_test_78 → Unique triples extracted: 2\n",
      "[79/1500] ID: ont_5_military_test_79 → Unique triples extracted: 1\n",
      "[80/1500] ID: ont_5_military_test_80 → Unique triples extracted: 1\n",
      "Batch 80-83 inference time: 52.53 seconds\n",
      "[81/1500] ID: ont_5_military_test_81 → Unique triples extracted: 1\n",
      "[82/1500] ID: ont_5_military_test_82 → Unique triples extracted: 1\n",
      "[83/1500] ID: ont_5_military_test_83 → Unique triples extracted: 1\n",
      "[84/1500] ID: ont_5_military_test_84 → Unique triples extracted: 2\n",
      "Batch 84-87 inference time: 70.99 seconds\n",
      "[85/1500] ID: ont_5_military_test_85 → Unique triples extracted: 1\n",
      "[86/1500] ID: ont_5_military_test_86 → Unique triples extracted: 1\n",
      "[87/1500] ID: ont_5_military_test_87 → Unique triples extracted: 1\n",
      "[88/1500] ID: ont_5_military_test_88 → Unique triples extracted: 2\n",
      "Batch 88-91 inference time: 49.47 seconds\n",
      "[89/1500] ID: ont_5_military_test_89 → Unique triples extracted: 1\n",
      "[90/1500] ID: ont_5_military_test_90 → Unique triples extracted: 3\n",
      "[91/1500] ID: ont_5_military_test_91 → Unique triples extracted: 1\n",
      "[92/1500] ID: ont_5_military_test_92 → Unique triples extracted: 1\n",
      "Batch 92-95 inference time: 92.67 seconds\n",
      "[93/1500] ID: ont_5_military_test_93 → Unique triples extracted: 1\n",
      "[94/1500] ID: ont_5_military_test_94 → Unique triples extracted: 1\n",
      "[95/1500] ID: ont_5_military_test_95 → Unique triples extracted: 1\n",
      "[96/1500] ID: ont_5_military_test_96 → Unique triples extracted: 1\n",
      "Batch 96-99 inference time: 51.06 seconds\n",
      "[97/1500] ID: ont_5_military_test_97 → Unique triples extracted: 4\n",
      "[98/1500] ID: ont_5_military_test_98 → Unique triples extracted: 1\n",
      "[99/1500] ID: ont_5_military_test_99 → Unique triples extracted: 1\n",
      "[100/1500] ID: ont_5_military_test_100 → Unique triples extracted: 2\n",
      "Batch 100-103 inference time: 93.01 seconds\n",
      "[101/1500] ID: ont_5_military_test_101 → Unique triples extracted: 1\n",
      "[102/1500] ID: ont_5_military_test_102 → Unique triples extracted: 1\n",
      "[103/1500] ID: ont_5_military_test_103 → Unique triples extracted: 1\n",
      "[104/1500] ID: ont_5_military_test_104 → Unique triples extracted: 1\n",
      "Batch 104-107 inference time: 42.07 seconds\n",
      "[105/1500] ID: ont_5_military_test_105 → Unique triples extracted: 2\n",
      "[106/1500] ID: ont_5_military_test_106 → Unique triples extracted: 2\n",
      "[107/1500] ID: ont_5_military_test_107 → Unique triples extracted: 2\n",
      "[108/1500] ID: ont_5_military_test_108 → Unique triples extracted: 1\n",
      "Batch 108-111 inference time: 72.48 seconds\n",
      "[109/1500] ID: ont_5_military_test_109 → Unique triples extracted: 2\n",
      "[110/1500] ID: ont_5_military_test_110 → Unique triples extracted: 3\n",
      "[111/1500] ID: ont_5_military_test_111 → Unique triples extracted: 1\n",
      "[112/1500] ID: ont_5_military_test_112 → Unique triples extracted: 1\n",
      "Batch 112-115 inference time: 92.95 seconds\n",
      "[113/1500] ID: ont_5_military_test_113 → Unique triples extracted: 1\n",
      "[114/1500] ID: ont_5_military_test_114 → Unique triples extracted: 1\n",
      "[115/1500] ID: ont_5_military_test_115 → Unique triples extracted: 1\n",
      "[116/1500] ID: ont_5_military_test_116 → Unique triples extracted: 1\n",
      "Batch 116-119 inference time: 52.84 seconds\n",
      "[117/1500] ID: ont_5_military_test_117 → Unique triples extracted: 3\n",
      "[118/1500] ID: ont_5_military_test_118 → Unique triples extracted: 1\n",
      "[119/1500] ID: ont_5_military_test_119 → Unique triples extracted: 3\n",
      "[120/1500] ID: ont_5_military_test_120 → Unique triples extracted: 1\n",
      "Batch 120-123 inference time: 92.84 seconds\n",
      "[121/1500] ID: ont_5_military_test_121 → Unique triples extracted: 2\n",
      "[122/1500] ID: ont_5_military_test_122 → Unique triples extracted: 6\n",
      "[123/1500] ID: ont_5_military_test_123 → Unique triples extracted: 5\n",
      "[124/1500] ID: ont_5_military_test_124 → Unique triples extracted: 4\n",
      "Batch 124-127 inference time: 73.76 seconds\n",
      "[125/1500] ID: ont_5_military_test_125 → Unique triples extracted: 1\n",
      "[126/1500] ID: ont_5_military_test_126 → Unique triples extracted: 1\n",
      "[127/1500] ID: ont_5_military_test_127 → Unique triples extracted: 4\n",
      "[128/1500] ID: ont_5_military_test_128 → Unique triples extracted: 2\n",
      "Batch 128-131 inference time: 11.10 seconds\n",
      "[129/1500] ID: ont_5_military_test_129 → Unique triples extracted: 2\n",
      "[130/1500] ID: ont_5_military_test_130 → Unique triples extracted: 3\n",
      "[131/1500] ID: ont_5_military_test_131 → Unique triples extracted: 6\n",
      "[132/1500] ID: ont_5_military_test_132 → Unique triples extracted: 3\n",
      "Batch 132-135 inference time: 33.10 seconds\n",
      "[133/1500] ID: ont_5_military_test_133 → Unique triples extracted: 2\n",
      "[134/1500] ID: ont_5_military_test_134 → Unique triples extracted: 4\n",
      "[135/1500] ID: ont_5_military_test_135 → Unique triples extracted: 4\n",
      "[136/1500] ID: ont_5_military_test_136 → Unique triples extracted: 1\n",
      "Batch 136-139 inference time: 37.36 seconds\n",
      "[137/1500] ID: ont_5_military_test_137 → Unique triples extracted: 3\n",
      "[138/1500] ID: ont_5_military_test_138 → Unique triples extracted: 1\n",
      "[139/1500] ID: ont_5_military_test_139 → Unique triples extracted: 5\n",
      "[140/1500] ID: ont_5_military_test_140 → Unique triples extracted: 11\n",
      "Batch 140-143 inference time: 25.11 seconds\n",
      "[141/1500] ID: ont_5_military_test_141 → Unique triples extracted: 0\n",
      "[142/1500] ID: ont_5_military_test_142 → Unique triples extracted: 6\n",
      "[143/1500] ID: ont_5_military_test_143 → Unique triples extracted: 7\n",
      "[144/1500] ID: ont_5_military_test_144 → Unique triples extracted: 5\n",
      "Batch 144-147 inference time: 85.65 seconds\n",
      "[145/1500] ID: ont_5_military_test_145 → Unique triples extracted: 1\n",
      "[146/1500] ID: ont_5_military_test_146 → Unique triples extracted: 1\n",
      "[147/1500] ID: ont_5_military_test_147 → Unique triples extracted: 1\n",
      "[148/1500] ID: ont_5_military_test_148 → Unique triples extracted: 1\n",
      "Batch 148-151 inference time: 68.49 seconds\n",
      "[149/1500] ID: ont_5_military_test_149 → Unique triples extracted: 1\n",
      "[150/1500] ID: ont_5_military_test_150 → Unique triples extracted: 1\n",
      "[151/1500] ID: ont_5_military_test_151 → Unique triples extracted: 5\n",
      "[152/1500] ID: ont_5_military_test_152 → Unique triples extracted: 1\n",
      "Batch 152-155 inference time: 51.76 seconds\n",
      "[153/1500] ID: ont_5_military_test_153 → Unique triples extracted: 4\n",
      "[154/1500] ID: ont_5_military_test_154 → Unique triples extracted: 2\n",
      "[155/1500] ID: ont_5_military_test_155 → Unique triples extracted: 3\n",
      "[156/1500] ID: ont_5_military_test_156 → Unique triples extracted: 1\n",
      "Batch 156-159 inference time: 54.87 seconds\n",
      "[157/1500] ID: ont_5_military_test_157 → Unique triples extracted: 7\n",
      "[158/1500] ID: ont_5_military_test_158 → Unique triples extracted: 5\n",
      "[159/1500] ID: ont_5_military_test_159 → Unique triples extracted: 3\n",
      "[160/1500] ID: ont_5_military_test_160 → Unique triples extracted: 1\n",
      "Batch 160-163 inference time: 52.04 seconds\n",
      "[161/1500] ID: ont_5_military_test_161 → Unique triples extracted: 5\n",
      "[162/1500] ID: ont_5_military_test_162 → Unique triples extracted: 1\n",
      "[163/1500] ID: ont_5_military_test_163 → Unique triples extracted: 3\n",
      "[164/1500] ID: ont_5_military_test_164 → Unique triples extracted: 1\n",
      "Batch 164-167 inference time: 74.30 seconds\n",
      "[165/1500] ID: ont_5_military_test_165 → Unique triples extracted: 1\n",
      "[166/1500] ID: ont_5_military_test_166 → Unique triples extracted: 5\n",
      "[167/1500] ID: ont_5_military_test_167 → Unique triples extracted: 1\n",
      "[168/1500] ID: ont_5_military_test_168 → Unique triples extracted: 1\n",
      "Batch 168-171 inference time: 52.21 seconds\n",
      "[169/1500] ID: ont_5_military_test_169 → Unique triples extracted: 2\n",
      "[170/1500] ID: ont_5_military_test_170 → Unique triples extracted: 2\n",
      "[171/1500] ID: ont_5_military_test_171 → Unique triples extracted: 9\n",
      "[172/1500] ID: ont_5_military_test_172 → Unique triples extracted: 1\n",
      "Batch 172-175 inference time: 54.74 seconds\n",
      "[173/1500] ID: ont_5_military_test_173 → Unique triples extracted: 8\n",
      "[174/1500] ID: ont_5_military_test_174 → Unique triples extracted: 1\n",
      "[175/1500] ID: ont_5_military_test_175 → Unique triples extracted: 3\n",
      "[176/1500] ID: ont_5_military_test_176 → Unique triples extracted: 1\n",
      "Batch 176-179 inference time: 28.91 seconds\n",
      "[177/1500] ID: ont_5_military_test_177 → Unique triples extracted: 1\n",
      "[178/1500] ID: ont_5_military_test_178 → Unique triples extracted: 4\n",
      "[179/1500] ID: ont_5_military_test_179 → Unique triples extracted: 2\n",
      "[180/1500] ID: ont_5_military_test_180 → Unique triples extracted: 3\n",
      "Batch 180-183 inference time: 34.21 seconds\n",
      "[181/1500] ID: ont_5_military_test_181 → Unique triples extracted: 1\n",
      "[182/1500] ID: ont_5_military_test_182 → Unique triples extracted: 2\n",
      "[183/1500] ID: ont_5_military_test_183 → Unique triples extracted: 11\n",
      "[184/1500] ID: ont_5_military_test_184 → Unique triples extracted: 1\n",
      "Batch 184-187 inference time: 92.30 seconds\n",
      "[185/1500] ID: ont_5_military_test_185 → Unique triples extracted: 1\n",
      "[186/1500] ID: ont_5_military_test_186 → Unique triples extracted: 1\n",
      "[187/1500] ID: ont_5_military_test_187 → Unique triples extracted: 1\n",
      "[188/1500] ID: ont_5_military_test_188 → Unique triples extracted: 2\n",
      "Batch 188-191 inference time: 35.89 seconds\n",
      "[189/1500] ID: ont_5_military_test_189 → Unique triples extracted: 1\n",
      "[190/1500] ID: ont_5_military_test_190 → Unique triples extracted: 2\n",
      "[191/1500] ID: ont_5_military_test_191 → Unique triples extracted: 1\n",
      "[192/1500] ID: ont_5_military_test_192 → Unique triples extracted: 1\n",
      "Batch 192-195 inference time: 34.06 seconds\n",
      "[193/1500] ID: ont_5_military_test_193 → Unique triples extracted: 1\n",
      "[194/1500] ID: ont_5_military_test_194 → Unique triples extracted: 1\n",
      "[195/1500] ID: ont_5_military_test_195 → Unique triples extracted: 5\n",
      "[196/1500] ID: ont_5_military_test_196 → Unique triples extracted: 3\n",
      "Batch 196-199 inference time: 36.77 seconds\n",
      "[197/1500] ID: ont_5_military_test_197 → Unique triples extracted: 1\n",
      "[198/1500] ID: ont_5_military_test_198 → Unique triples extracted: 1\n",
      "[199/1500] ID: ont_5_military_test_199 → Unique triples extracted: 1\n",
      "[200/1500] ID: ont_5_military_test_200 → Unique triples extracted: 1\n",
      "Batch 200-203 inference time: 26.72 seconds\n",
      "[201/1500] ID: ont_5_military_test_201 → Unique triples extracted: 1\n",
      "[202/1500] ID: ont_5_military_test_202 → Unique triples extracted: 1\n",
      "[203/1500] ID: ont_5_military_test_203 → Unique triples extracted: 1\n",
      "[204/1500] ID: ont_5_military_test_204 → Unique triples extracted: 1\n",
      "Batch 204-207 inference time: 70.30 seconds\n",
      "[205/1500] ID: ont_5_military_test_205 → Unique triples extracted: 1\n",
      "[206/1500] ID: ont_5_military_test_206 → Unique triples extracted: 1\n",
      "[207/1500] ID: ont_5_military_test_207 → Unique triples extracted: 1\n",
      "[208/1500] ID: ont_5_military_test_208 → Unique triples extracted: 1\n",
      "Batch 208-211 inference time: 51.41 seconds\n",
      "[209/1500] ID: ont_5_military_test_209 → Unique triples extracted: 1\n",
      "[210/1500] ID: ont_5_military_test_210 → Unique triples extracted: 2\n",
      "[211/1500] ID: ont_5_military_test_211 → Unique triples extracted: 4\n",
      "[212/1500] ID: ont_5_military_test_212 → Unique triples extracted: 1\n",
      "Batch 212-215 inference time: 71.27 seconds\n",
      "[213/1500] ID: ont_5_military_test_213 → Unique triples extracted: 3\n",
      "[214/1500] ID: ont_5_military_test_214 → Unique triples extracted: 2\n",
      "[215/1500] ID: ont_5_military_test_215 → Unique triples extracted: 2\n",
      "[216/1500] ID: ont_5_military_test_216 → Unique triples extracted: 1\n",
      "Batch 216-219 inference time: 33.77 seconds\n",
      "[217/1500] ID: ont_5_military_test_217 → Unique triples extracted: 10\n",
      "[218/1500] ID: ont_5_military_test_218 → Unique triples extracted: 1\n",
      "[219/1500] ID: ont_5_military_test_219 → Unique triples extracted: 1\n",
      "[220/1500] ID: ont_5_military_test_220 → Unique triples extracted: 11\n",
      "Batch 220-223 inference time: 60.92 seconds\n",
      "[221/1500] ID: ont_5_military_test_221 → Unique triples extracted: 1\n",
      "[222/1500] ID: ont_5_military_test_222 → Unique triples extracted: 1\n",
      "[223/1500] ID: ont_5_military_test_223 → Unique triples extracted: 10\n",
      "[224/1500] ID: ont_5_military_test_224 → Unique triples extracted: 4\n",
      "Batch 224-227 inference time: 81.20 seconds\n",
      "[225/1500] ID: ont_5_military_test_225 → Unique triples extracted: 1\n",
      "[226/1500] ID: ont_5_military_test_226 → Unique triples extracted: 1\n",
      "[227/1500] ID: ont_5_military_test_227 → Unique triples extracted: 2\n",
      "[228/1500] ID: ont_5_military_test_228 → Unique triples extracted: 1\n",
      "Batch 228-229 inference time: 8.33 seconds\n",
      "[229/1500] ID: ont_5_military_test_229 → Unique triples extracted: 3\n",
      "[230/1500] ID: ont_5_military_test_230 → Unique triples extracted: 9\n",
      "\n",
      "✅ All 230 prompts processed. Results saved to: /upb/users/b/balram/profiles/unix/cs/Text2KG/withont/data/wikidata/response_run3/Mistral/cot_response_without_quant_batch/ont_5_military_llm_response_improved.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    input_file = '/upb/users/b/balram/profiles/unix/cs/Text2KG/withont/data/wikidata/input_prompts/cot_prompts/ont_5_military_prompts_improved.jsonl'\n",
    "    output_file = \"/upb/users/b/balram/profiles/unix/cs/Text2KG/withont/data/wikidata/response_run3/Mistral/cot_response_without_quant_batch/ont_5_military_llm_response_improved.jsonl\"\n",
    "    text_pipe, tokenizer = setup_model(\"mistralai/Mistral-7B-Instruct-v0.3\")\n",
    "    main(input_file, output_file, text_pipe, tokenizer, num_prompts=1500, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5329b6e-2ce2-4386-8b46-cf6c88d44bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd8a0a2-b23f-4341-be2a-3aea64286f76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KG Pipeline (GPU)",
   "language": "python",
   "name": "kg_pipeline"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
