{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d7c643-d5ca-42a0-9380-fd8355c2e393",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70be4b8d-4ca9-46c6-929a-c58e83cf0fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def read_jsonl_file(filepath):\n",
    "    \"\"\"\n",
    "    Reads the JSONL file and returns a list of dictionaries.\n",
    "    \n",
    "    Args:\n",
    "        filepath (str): Path to the JSONL file.\n",
    "    \n",
    "    Returns:\n",
    "        data (list): A list of dictionaries containing the data from the JSONL file.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            data.append(json.loads(line.strip()))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7328dcb4-f291-4213-a93d-2f8a781ced7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_numerical_data(data):\n",
    "    \"\"\"\n",
    "    Extracts numerical fields from each entry in the data.\n",
    "    \n",
    "    Args:\n",
    "        data (list): A list of dictionaries containing data from the JSONL file.\n",
    "    \n",
    "    Returns:\n",
    "        numerical_data (dict): A dictionary containing lists of numerical values for each field.\n",
    "    \"\"\"\n",
    "    numerical_data = {\n",
    "        \"precision\": [],\n",
    "        \"recall\": [],\n",
    "        \"f1\": [],\n",
    "        \"onto_conf\": [],\n",
    "        \"rel_halluc\": [],\n",
    "        \"sub_halluc\": [],\n",
    "        \"obj_halluc\": []\n",
    "    }\n",
    "    \n",
    "    for entry in data:\n",
    "        numerical_data[\"precision\"].append(float(entry.get(\"precision\", 0.0)))\n",
    "        numerical_data[\"recall\"].append(float(entry.get(\"recall\", 0.0)))\n",
    "        numerical_data[\"f1\"].append(float(entry.get(\"f1\", 0.0)))\n",
    "        numerical_data[\"onto_conf\"].append(float(entry.get(\"onto_conf\", 0.0)))\n",
    "        numerical_data[\"rel_halluc\"].append(float(entry.get(\"rel_halluc\", 0.0)))\n",
    "        numerical_data[\"sub_halluc\"].append(float(entry.get(\"sub_halluc\", 0.0)))\n",
    "        numerical_data[\"obj_halluc\"].append(float(entry.get(\"obj_halluc\", 0.0)))\n",
    "    \n",
    "    return numerical_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bc5cc70b-5e77-48a7-b348-6857f8e9b2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_averages(numerical_data):\n",
    "    \"\"\"\n",
    "    Calculates the average for each numerical field and returns them with prefixed keys.\n",
    "    \n",
    "    Args:\n",
    "        numerical_data (dict): A dictionary containing lists of numerical values for each field.\n",
    "    \n",
    "    Returns:\n",
    "        averages (dict): A dictionary containing the average values for each field, with \"avg_\" prefix.\n",
    "    \"\"\"\n",
    "    averages = {\n",
    "        \"avg_precision\": 0.0,\n",
    "        \"avg_recall\": 0.0,\n",
    "        \"avg_f1\": 0.0,\n",
    "        \"avg_onto_conf\": 0.0,\n",
    "        \"avg_rel_halluc\": 0.0,\n",
    "        \"avg_sub_halluc\": 0.0,\n",
    "        \"avg_obj_halluc\": 0.0\n",
    "    }\n",
    "    \n",
    "    for key, values in numerical_data.items():\n",
    "        avg_key = f\"avg_{key}\"\n",
    "        if values:\n",
    "            averages[avg_key] = sum(values) / len(values)\n",
    "    \n",
    "    return averages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "65a59a83-e15b-4951-b89a-7d30da65fbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_jsonl(data, output_filepath):\n",
    "    \"\"\"\n",
    "    Saves a list of dictionaries to a JSONL file.\n",
    "    \n",
    "    Args:\n",
    "        data (list): A list of dictionaries containing average values for each file.\n",
    "        output_filepath (str): The path to the output JSONL file.\n",
    "    \"\"\"\n",
    "    with open(output_filepath, 'w', encoding='utf-8') as file:\n",
    "        for record in data:\n",
    "            json.dump(record, file)\n",
    "            file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "18775516-6464-42a4-a0fe-b1c03f6167c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_multiple_files(files, output_filepath):\n",
    "    \"\"\"\n",
    "    Processes multiple files to calculate and save their average statistics.\n",
    "    \n",
    "    Args:\n",
    "        files (list): A list of tuples where each tuple contains:\n",
    "                      - the filepath to the file\n",
    "                      - the ontology name (e.g., \"1_movie\", \"2_music\")\n",
    "        output_filepath (str): The path to the output JSONL file.\n",
    "    \"\"\"\n",
    "    all_results = []\n",
    "    \n",
    "    for filepath, ontology in files:\n",
    "        # Step 1: Read the JSONL file\n",
    "        data = read_jsonl_file(filepath)\n",
    "        \n",
    "        # Step 2: Extract numerical data\n",
    "        numerical_data = extract_numerical_data(data)\n",
    "        \n",
    "        # Step 3: Calculate averages for \"all_test_cases\"\n",
    "        averages_all = calculate_averages(numerical_data)\n",
    "        averages_all.update({\"onto\": ontology, \"type\": \"all_test_cases\"})\n",
    "        all_results.append(averages_all)\n",
    "        \n",
    "    \n",
    "    # Step 5: Save all the results to a single JSONL file\n",
    "    save_to_jsonl(all_results, output_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "523c6cd7-312f-4ae1-b8ac-ed84e84b4a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\n",
    "    (\"../data/dbpedia_webnig/alpha_vicuna/vicuna/improvised_evaluation_statistics/ont_1_university_llm_stats.jsonl\", \"1_university\"),\n",
    "    (\"../data/dbpedia_webnig/alpha_vicuna/vicuna/improvised_evaluation_statistics/ont_2_musicalwork_llm_stats.jsonl\", \"2_musicalwork\"),\n",
    "    (\"../data/dbpedia_webnig/alpha_vicuna/vicuna/improvised_evaluation_statistics/ont_3_airport_llm_stats.jsonl\", \"3_airport\"),\n",
    "    (\"../data/dbpedia_webnig/alpha_vicuna/vicuna/improvised_evaluation_statistics/ont_4_building_llm_stats.jsonl\", \"4_building\"),\n",
    "    (\"../data/dbpedia_webnig/alpha_vicuna/vicuna/improvised_evaluation_statistics/ont_5_athlete_llm_stats.jsonl\", \"5_athlete\"),\n",
    "    (\"../data/dbpedia_webnig/alpha_vicuna/vicuna/improvised_evaluation_statistics/ont_6_politician_llm_stats.jsonl\", \"6_politician\"),\n",
    "    (\"../data/dbpedia_webnig/alpha_vicuna/vicuna/improvised_evaluation_statistics/ont_7_company_llm_stats.jsonl\", \"7_company\"),\n",
    "    (\"../data/dbpedia_webnig/alpha_vicuna/vicuna/improvised_evaluation_statistics/ont_8_celestialbody_llm_stats.jsonl\", \"8_celestialbody\"),\n",
    "    (\"../data/dbpedia_webnig/alpha_vicuna/vicuna/improvised_evaluation_statistics/ont_9_astronaut_llm_stats.jsonl\", \"9_astronaut\"),\n",
    "    (\"../data/dbpedia_webnig/alpha_vicuna/vicuna/improvised_evaluation_statistics/ont_10_comicscharacter_llm_stats.jsonl\", \"10_comicscharacter\"),\n",
    "    (\"../data/dbpedia_webnig/alpha_vicuna/vicuna/improvised_evaluation_statistics/ont_11_meanoftransportation_llm_stats.jsonl\", \"11_meanoftransportation\"),\n",
    "    (\"../data/dbpedia_webnig/alpha_vicuna/vicuna/improvised_evaluation_statistics/ont_12_monument_llm_stats.jsonl\", \"12_monument\"),\n",
    "    (\"../data/dbpedia_webnig/alpha_vicuna/vicuna/improvised_evaluation_statistics/ont_13_food_llm_stats.jsonl\", \"13_food\"),\n",
    "    (\"../data/dbpedia_webnig/alpha_vicuna/vicuna/improvised_evaluation_statistics/ont_14_writtenwork_llm_stats.jsonl\", \"14_writtenwork\"),\n",
    "    (\"../data/dbpedia_webnig/alpha_vicuna/vicuna/improvised_evaluation_statistics/ont_15_sportsteam_llm_stats.jsonl\", \"15_sportsteam\"),\n",
    "    (\"../data/dbpedia_webnig/alpha_vicuna/vicuna/improvised_evaluation_statistics/ont_16_city_llm_stats.jsonl\", \"16_city\"),\n",
    "    (\"../data/dbpedia_webnig/alpha_vicuna/vicuna/improvised_evaluation_statistics/ont_17_artist_llm_stats.jsonl\", \"17_artist\"),\n",
    "    (\"../data/dbpedia_webnig/alpha_vicuna/vicuna/improvised_evaluation_statistics/ont_18_scientist_llm_stats.jsonl\", \"18_scientist\"),\n",
    "    (\"../data/dbpedia_webnig/alpha_vicuna/vicuna/improvised_evaluation_statistics/ont_19_film_llm_stats.jsonl\", \"19_film\"),\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "OUTPUT_FILEPATH = '/upb/users/b/balram/profiles/unix/cs/Text2KG/withont/data/dbpedia_webnig/alpha_vicuna/vicuna/overall_avg_statistics/vicuna_overall_averages_without_missing_GT_improvised_evaluation.jsonl'\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KG Pipeline (GPU)",
   "language": "python",
   "name": "kg_pipeline"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
