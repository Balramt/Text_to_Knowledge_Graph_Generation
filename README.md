# Leveraging Large Language Models for KG Construction and Reasoning
---
This repository is part of the research project on **Leveraging Large Language Models for KG Construction and Reasoning** using Large Language Models (LLMs). The benchmark aims to evaluate LLMs for extracting knowledge graph triples from natural language while adhering to a given ontology. The focus is on key evaluation metrics such as precision, recall, F1-score, ontology conformance, and hallucination rates.

---
## ğŸ§  `src/` â€“ Main Source Directory
The `src` directory contains all the code for running LLMs, generating RDF triples, and evaluating outputs. It is organized into submodules for evaluation and model generation.
---
### ğŸ“‚ [`evaluation`](https://github.com/Balramt/Text_to_Knowledge_Graph_Generation/tree/main/src/evaluation)
Scripts to evaluate the triples extracted from LLM responses.
* ğŸ“˜ **[Baseline Evaluation](https://github.com/Balramt/Text_to_Knowledge_Graph_Generation/blob/main/src/evaluation/Baseline_evaluation.ipynb)**
  Evaluates precision, recall, F1, and hallucinations (ontology, subject, object, relation) using raw LLM outputs.
* ğŸ› ï¸ **[Improvised Evaluation](https://github.com/Balramt/Text_to_Knowledge_Graph_Generation/blob/main/src/evaluation/Evaluation_improvised.ipynb)**
  More robust evaluation that cleans special characters and symbols for accurate matching.
---
### ğŸ¤– [`llm_models`](https://github.com/Balramt/Text_to_Knowledge_Graph_Generation/tree/main/src/llm_models)
LLM-based triple generation modules.
* ğŸ”¹ **[LLaMA](https://github.com/Balramt/Text_to_Knowledge_Graph_Generation/blob/main/src/llm_models/Llama3_with_batch_without_quant.ipynb)**
  Uses LLaMA to generate text and extract triples from structured prompts.
* ğŸ”¹ **[Mistral](https://github.com/Balramt/Text_to_Knowledge_Graph_Generation/blob/main/src/llm_models/Mistral_Batch.ipynb)**
  Parallel implementation using Mistral model to generate and parse triples from prompts.
---

## ğŸ“¦ Data Structure Overview
---
### ğŸ—‚ï¸ `wikidata_tekgen`
* [Wikidata-TekGen](https://github.com/Balramt/Text_to_Knowledge_Graph_Generation/tree/main/data/wikidata)
* **Ontologies (10)**: [ontologies](https://github.com/Balramt/Text_to_Knowledge_Graph_Generation/tree/main/data/wikidata/ontology) â€“ Ontology files used for triple validation.
* **Ground Truth**: [ground\_truth](https://github.com/Balramt/Text_to_Knowledge_Graph_Generation/tree/main/data/wikidata/ground_truth) â€“ Gold standard triples for evaluation.
* **Prompts**: [prompts](https://github.com/Balramt/Text_to_Knowledge_Graph_Generation/tree/main/data/wikidata/prompts) â€“ Natural language prompts generated for test samples.
  
#### ğŸ“Š Baselines â€“ Evaluation Results and LLM Responses
##### ğŸ”¹ Alpaca-LoRA-13B
* [Alpaca Data](https://github.com/Balramt/Text_to_Knowledge_Graph_Generation/tree/main/data/wikidata/baselines/Alpaca-LoRA-13B)
  * [llm\_responses](https://github.com/Balramt/Text_to_Knowledge_Graph_Generation/tree/main/data/wikidata/baselines/Alpaca-LoRA-13B/llm_response) â€“ Raw responses + extracted triples
  * [eval\_metrics](https://github.com/Balramt/Text_to_Knowledge_Graph_Generation/tree/main/data/wikidata/baselines/Alpaca-LoRA-13B/evaluation_statistics/baseline_statistics) â€“ Ontology-level + aggregated results
##### ğŸ”¹ Vicuna-13B
* [Vicuna Data](https://github.com/Balramt/Text_to_Knowledge_Graph_Generation/tree/main/data/wikidata/baselines/Vicuna-13B)
  * [llm\_responses](https://github.com/Balramt/Text_to_Knowledge_Graph_Generation/tree/main/data/wikidata/baselines/Vicuna-13B/llm_response) â€“ Raw responses + extracted triples
  * [eval\_metrics](https://github.com/Balramt/Text_to_Knowledge_Graph_Generation/tree/main/data/wikidata/baselines/Vicuna-13B/evaluation_statistics/baseline_statistics) â€“ Ontology-level + aggregated results
##### ğŸ”¹ Llama-8B
* [Llama Data](https://github.com/Balramt/Text_to_Knowledge_Graph_Generation/tree/main/data/wikidata/baselines/Llama-8B)
  * [llm\_responses](https://github.com/Balramt/Text_to_Knowledge_Graph_Generation/tree/main/data/wikidata/baselines/Llama-8B/llm_response) â€“ Raw responses + extracted triples
  * [eval\_metrics](https://github.com/Balramt/Text_to_Knowledge_Graph_Generation/tree/main/data/wikidata/baselines/Llama-8B/evaluation_statistics) â€“ Ontology-level + aggregated results
##### ğŸ”¹ Mistral-7B
* [Mistral Data](https://github.com/Balramt/Text_to_Knowledge_Graph_Generation/tree/main/data/wikidata/baselines/Mistral-7B)
  * [llm\_responses](https://github.com/Balramt/Text_to_Knowledge_Graph_Generation/tree/main/data/wikidata/baselines/Mistral-7B/llm_response) â€“ Raw responses + extracted triples
  * [eval\_metrics](https://github.com/Balramt/Text_to_Knowledge_Graph_Generation/tree/main/data/wikidata/baselines/Mistral-7B/evaluation_statistics) â€“ Ontology-level + aggregated results
---

### ğŸ—‚ï¸ `dbpedia_webnlg`
* [DBpedia-Webnlg](https://github.com/Balramt/Text_to_Knowledge_Graph_Generation/tree/main/data/dbpedia)
* **Ontologies (19)**: [ontologies](https://github.com/Balramt/Text_to_Knowledge_Graph_Generation/tree/main/data/dbpedia/ontology) â€“ DBpedia ontologies for triple evaluation.
* **Ground Truth**: [ground\_truth](https://github.com/Balramt/Text_to_Knowledge_Graph_Generation/tree/main/data/dbpedia/ground_truth) â€“ Gold standard triple data.
* **Prompts**: [prompts](https://github.com/Balramt/Text_to_Knowledge_Graph_Generation/tree/main/data/dbpedia/prompts) â€“ Prompt files for LLM-based triple generation.

#### ğŸ“Š Baselines â€“ Evaluation Results and LLM Responses
##### ğŸ”¹ Alpaca-LoRA-13B
* [Alpaca Data](https://github.com/Balramt/Text_to_Knowledge_Graph_Generation/tree/main/data/dbpedia/baselines/Alpaca-LoRA-13B)
  * [llm\_responses](https://github.com/Balramt/Text_to_Knowledge_Graph_Generation/tree/main/data/dbpedia/baselines/Alpaca-LoRA-13B/llm_response) â€“ Raw responses + extracted triples
  * [eval\_metrics](https://github.com/Balramt/Text_to_Knowledge_Graph_Generation/tree/main/data/dbpedia/baselines/Alpaca-LoRA-13B/evaluation_statistics/baseline_statistics) â€“ Ontology-level + aggregated results
##### ğŸ”¹ Vicuna-13B
* [Vicuna Data](https://github.com/Balramt/Text_to_Knowledge_Graph_Generation/tree/main/data/dbpedia/baselines/Vicuna-13B)
  * [llm\_responses](https://github.com/Balramt/Text_to_Knowledge_Graph_Generation/tree/main/data/dbpedia/baselines/Vicuna-13B/llm_response) â€“ Raw responses + extracted triples
  * [eval\_metrics](https://github.com/Balramt/Text_to_Knowledge_Graph_Generation/tree/main/data/dbpedia/baselines/Vicuna-13B/evaluation_statistics/baseline_statistics) â€“ Ontology-level + aggregated results
##### ğŸ”¹ Llama-8B
* [Llama Data](https://github.com/Balramt/Text_to_Knowledge_Graph_Generation/tree/main/data/dbpedia/baselines/Llama-8B)
  * [llm\_responses](https://github.com/Balramt/Text_to_Knowledge_Graph_Generation/tree/main/data/dbpedia/baselines/Llama-8B/llm_response) â€“ Raw responses + extracted triples
  * [eval\_metrics](https://github.com/Balramt/Text_to_Knowledge_Graph_Generation/tree/main/data/dbpedia/baselines/Llama-8B/evaluation_statistics) â€“ Ontology-level + aggregated results
##### ğŸ”¹ Mistral-7B
* [Mistral Data](https://github.com/Balramt/Text_to_Knowledge_Graph_Generation/tree/main/data/dbpedia/baselines/Mistral-7B)
  * [llm\_responses](https://github.com/Balramt/Text_to_Knowledge_Graph_Generation/tree/main/data/dbpedia/baselines/Mistral-7B/llm_response) â€“ Raw responses + extracted triples
  * [eval\_metrics](https://github.com/Balramt/Text_to_Knowledge_Graph_Generation/tree/main/data/dbpedia/baselines/Mistral-7B/evaluation_statistics) â€“ Ontology-level + aggregated results
---

## ğŸ§ª How to Use

This structure supports:

* Reproducing experiments using the provided prompts and ground truths
* Comparing LLM outputs against baseline evaluations
* Loading ontologies and results into custom tools or visualizers

---

## ğŸ“ Folder Tree (Example)

```
data/
â”œâ”€â”€ dbpedia/
â”‚   â”œâ”€â”€ ontologies/
â”‚   â”œâ”€â”€ ground_truth/
â”‚   â”œâ”€â”€ input_prompts/
â”‚   â””â”€â”€ baselines/
â”‚       â”œâ”€â”€ Alpaca-LoRA-13B/
â”‚       â””â”€â”€ Vicuna-13B/
â””â”€â”€ wikidata/
    â”œâ”€â”€ ontologies/
    â”œâ”€â”€ ground_truth/
    â”œâ”€â”€ input_prompts/
    â””â”€â”€ baselines/
        â”œâ”€â”€ Alpaca-LoRA-13B/
        â””â”€â”€ Vicuna-13B/
```

---
