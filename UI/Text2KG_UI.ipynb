{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a32720-a94d-4b60-b81f-69da10bbefe4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920274fd-534e-4c78-8909-d783ed0c467d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fc0ab7-c130-4237-a58e-aace3b0a3954",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8136150c-1413-493a-8123-c7d03bf5ac74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /upb/users/b/balram/profiles/unix/cs/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /upb/users/b/balram/profiles/unix/cs/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://0.0.0.0:8070/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f5d97b618d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:03<00:00,  1.07s/it]\n",
      "Device set to use cuda:0\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "import dash\n",
    "from dash import dcc, html, Input, Output, State, ctx, dash_table\n",
    "import dash_bootstrap_components as dbc\n",
    "import base64\n",
    "import tempfile\n",
    "import os\n",
    "import jsonlines\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "import re\n",
    "import json\n",
    "import hashlib\n",
    "import nltk\n",
    "import dash_cytoscape as cyto\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "app = dash.Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP], suppress_callback_exceptions=True)\n",
    "app.title = \"Prompt-Ontology Triple Extractor\"\n",
    "\n",
    "# ------------------- Normalization -------------------\n",
    "\n",
    "def clean_triple_component(text):\n",
    "    text = text.lower().replace(\"_\", \" \")\n",
    "    text = re.sub(r\"[^a-z0-9 ]\", \"\", text)\n",
    "    text = text.strip()\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmatized = \" \".join(lemmatizer.lemmatize(token) for token in tokens)\n",
    "    return lemmatized\n",
    "\n",
    "# ------------------- Model Setup Functions -------------------\n",
    "\n",
    "def setup_llama_model():\n",
    "    model_id = \"meta-llama/Meta-Llama-3-8B\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"auto\", torch_dtype=torch.float16)\n",
    "    model.config.use_cache = False\n",
    "    pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device_map=\"auto\")\n",
    "    return pipe, tokenizer\n",
    "\n",
    "def setup_mistral_model():\n",
    "    model_id = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"auto\", torch_dtype=torch.float16)\n",
    "    pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device_map=\"auto\")\n",
    "    return pipe, tokenizer\n",
    "\n",
    "# ------------------- Output Parsing -------------------\n",
    "\n",
    "def extract_test_outputs(response):\n",
    "    outputs = []\n",
    "    for res in response:\n",
    "        generated_text = res.get('generated_text', '')\n",
    "        match = re.search(r'Test Output:\\s*(.*?)(?=\\n\\s*#|$)', generated_text, re.DOTALL)\n",
    "        if match:\n",
    "            outputs.append(match.group(1).strip())\n",
    "    return outputs if outputs else ['Output not found']\n",
    "\n",
    "def parse_model_output(model_output):\n",
    "    triples = []\n",
    "    pattern = re.compile(r'(.+?)\\s*\\(([^,]+),\\s*([^)]+)\\)')\n",
    "    lines = model_output.strip().split('\\n')\n",
    "    for line in lines:\n",
    "        for match in pattern.findall(line):\n",
    "            rel, sub, obj = match\n",
    "            triples.append({\n",
    "                \"sub\": clean_triple_component(sub),\n",
    "                \"rel\": clean_triple_component(rel),\n",
    "                \"obj\": clean_triple_component(obj)\n",
    "            })\n",
    "    return triples\n",
    "\n",
    "# ------------------- Graph Utilities -------------------\n",
    "\n",
    "def color_for_node(node_id):\n",
    "    h = hashlib.md5(node_id.encode()).hexdigest()\n",
    "    return '#' + h[:6]\n",
    "\n",
    "def sanitize_id(text, max_length=20):\n",
    "    sanitized = re.sub(r'\\W+', '_', text)\n",
    "    if len(sanitized) > max_length:\n",
    "        hashed = hashlib.md5(text.encode()).hexdigest()[:8]\n",
    "        sanitized = sanitized[:max_length-9] + '_' + hashed\n",
    "    return sanitized\n",
    "\n",
    "def triples_to_cytoscape_elements(triples):\n",
    "    elements, nodes = [], set()\n",
    "    edge_dict = {}\n",
    "    for triple in triples:\n",
    "        s, p, o = triple['sub'], triple['rel'], triple['obj']\n",
    "        s_id = sanitize_id(s)\n",
    "        o_id = sanitize_id(o)\n",
    "        if s_id not in nodes:\n",
    "            elements.append({'data': {'id': s_id, 'label': s, 'fullLabel': s}, 'style': {'background-color': color_for_node(s)}})\n",
    "            nodes.add(s_id)\n",
    "        if o_id not in nodes:\n",
    "            elements.append({'data': {'id': o_id, 'label': o, 'fullLabel': o}, 'style': {'background-color': color_for_node(o)}})\n",
    "            nodes.add(o_id)\n",
    "        key = (s_id, o_id)\n",
    "        edge_dict.setdefault(key, set()).add((p, s, o))\n",
    "\n",
    "    processed = set()\n",
    "    for (src, tgt), rel_info_set in list(edge_dict.items()):\n",
    "        rels = [rel for rel, _, _ in rel_info_set]\n",
    "        label = ', '.join(sorted(rels))\n",
    "        if (tgt, src) in edge_dict and (tgt, src) not in processed:\n",
    "            rels_opposite = [rel for rel, _, _ in edge_dict[(tgt, src)]]\n",
    "            label = ', '.join(sorted(set(rels + rels_opposite)))\n",
    "            elements.append({'data': {'id': f'{src}_bi_{tgt}', 'source': src, 'target': tgt, 'label': label, 'fullLabel': label}, 'classes': 'bidirectional'})\n",
    "            processed.add((src, tgt))\n",
    "            processed.add((tgt, src))\n",
    "        elif (src, tgt) not in processed:\n",
    "            rel, sub, obj = list(rel_info_set)[0]\n",
    "            elements.append({'data': {'id': f'{src}_{tgt}_{label}', 'source': src, 'target': tgt, 'label': label, 'fullLabel': label, 'sub': sub, 'rel': label, 'obj': obj}})\n",
    "            processed.add((src, tgt))\n",
    "    return elements\n",
    "\n",
    "# ------------------- UI Layout -------------------\n",
    "\n",
    "app.layout = dbc.Container([\n",
    "    html.H2(\"Triple Extractor using LLaMA-3 / Mistral\"),\n",
    "    dbc.Row([\n",
    "        dbc.Col(dcc.Upload(id='upload-prompt', children=html.Div([\"Upload Prompt JSONL\"]), multiple=False), width=6),\n",
    "        dbc.Col(dcc.Upload(id='upload-ontology', children=html.Div([\"Upload Ontology JSON\"]), multiple=False), width=6),\n",
    "    ]),\n",
    "    html.Br(),\n",
    "    dbc.Row([\n",
    "        dbc.Col(dcc.Dropdown(id='model-selector', options=[{\"label\": \"LLaMA 3 (Meta)\", \"value\": \"llama\"}, {\"label\": \"Mistral 7B\", \"value\": \"mistral\"}], value=\"mistral\", clearable=False), width=4),\n",
    "        dbc.Col(dbc.RadioItems(id='view-selector', options=[{\"label\": \"Table View\", \"value\": \"table\"}, {\"label\": \"Graph View\", \"value\": \"graph\"}], value=\"table\", inline=True), width=6),\n",
    "        dbc.Col(dbc.Button(\"Run Extraction\", id=\"run-btn\", color=\"primary\"), width=\"auto\"),\n",
    "    ]),\n",
    "    html.Div(id=\"status\", style={\"marginTop\": 20}),\n",
    "    html.Hr(),\n",
    "    dcc.Store(id='triples-store'),\n",
    "    html.Div(id=\"result-output\"),\n",
    "    html.Div(id='cytoscape-description', style={'marginTop': '20px'}),\n",
    "    dcc.Store(id='cy-elements-store'),\n",
    "])\n",
    "\n",
    "# ------------------- Callbacks -------------------\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"status\", \"children\"),\n",
    "    Output(\"triples-store\", \"data\"),\n",
    "    Output(\"cy-elements-store\", \"data\"),\n",
    "    Input(\"run-btn\", \"n_clicks\"),\n",
    "    State(\"model-selector\", \"value\"),\n",
    "    State(\"upload-prompt\", \"contents\"),\n",
    "    State(\"upload-prompt\", \"filename\"),\n",
    "    State(\"upload-ontology\", \"contents\"),\n",
    "    State(\"upload-ontology\", \"filename\"),\n",
    "    prevent_initial_call=True\n",
    ")\n",
    "def run_extraction(n_clicks, selected_model, prompt_content, prompt_name, ontology_content, ontology_name):\n",
    "    if not prompt_content:\n",
    "        return \"Please upload prompt file.\", None, []\n",
    "\n",
    "    prompt_type, prompt_str = prompt_content.split(',')\n",
    "    prompt_data = base64.b64decode(prompt_str)\n",
    "    with tempfile.NamedTemporaryFile(delete=False, suffix=\".jsonl\") as f:\n",
    "        f.write(prompt_data)\n",
    "        prompt_path = f.name\n",
    "\n",
    "    prompts = list(jsonlines.open(prompt_path))\n",
    "\n",
    "    generator, tokenizer = setup_llama_model() if selected_model == \"llama\" else setup_mistral_model()\n",
    "\n",
    "    results = []\n",
    "    for idx, item in enumerate(prompts[:10]):\n",
    "        try:\n",
    "            response = generator(item[\"prompt\"], max_new_tokens=512, num_return_sequences=2, temperature=0.2)\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "        test_outputs = extract_test_outputs(response)\n",
    "        all_triples = []\n",
    "        seen = set()\n",
    "        for out in test_outputs:\n",
    "            triples = parse_model_output(out)\n",
    "            for t in triples:\n",
    "                key = (t[\"sub\"], t[\"rel\"], t[\"obj\"])\n",
    "                if key not in seen:\n",
    "                    seen.add(key)\n",
    "                    all_triples.append(t)\n",
    "        results.append({\"id\": item[\"id\"], \"triples\": all_triples})\n",
    "\n",
    "    all_cleaned_triples = []\n",
    "    for res in results:\n",
    "        for triple in res[\"triples\"]:\n",
    "            all_cleaned_triples.append({\"ID\": res[\"id\"], **triple})\n",
    "\n",
    "    cy_elements = triples_to_cytoscape_elements(all_cleaned_triples)\n",
    "    return f\"Processed {len(results)} prompts using {selected_model.title()} model.\", all_cleaned_triples, cy_elements\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"result-output\", \"children\"),\n",
    "    Input(\"view-selector\", \"value\"),\n",
    "    State(\"triples-store\", \"data\"),\n",
    "    State(\"cy-elements-store\", \"data\"),\n",
    "    prevent_initial_call=True\n",
    ")\n",
    "def update_view(view_mode, triples, elements):\n",
    "    if view_mode == \"table\":\n",
    "        return dash_table.DataTable(\n",
    "            columns=[{\"name\": c, \"id\": c} for c in [\"ID\", \"sub\", \"rel\", \"obj\"]],\n",
    "            data=triples or [],\n",
    "            page_size=10,\n",
    "            style_table={\"overflowX\": \"auto\"}\n",
    "        )\n",
    "    else:\n",
    "        return cyto.Cytoscape(\n",
    "            id='cytoscape-graph',\n",
    "            layout={'name': 'cose'},\n",
    "            style={'width': '100%', 'height': '600px', 'border': '1px solid black'},\n",
    "            elements=elements or [],\n",
    "            stylesheet=[\n",
    "                {'selector': 'node', 'style': {'content': 'data(label)', 'text-valign': 'center', 'text-halign': 'center', 'width': '50px', 'height': '50px', 'font-size': '14px', 'font-weight': 'bold'}},\n",
    "                {'selector': 'edge', 'style': {'label': 'data(label)', 'curve-style': 'bezier', 'target-arrow-shape': 'triangle', 'arrow-scale': 1.5, 'line-color': '#A9A9A9', 'target-arrow-color': '#A9A9A9', 'font-size': '11px', 'text-rotation': 'autorotate'}},\n",
    "                {'selector': '.bidirectional', 'style': {'source-arrow-shape': 'triangle', 'target-arrow-shape': 'triangle', 'line-color': '#0074D9', 'source-arrow-color': '#0074D9', 'target-arrow-color': '#0074D9', 'font-weight': 'bold'}}\n",
    "            ]\n",
    "        )\n",
    "\n",
    "@app.callback(\n",
    "    Output('cytoscape-description', 'children'),\n",
    "    Input('cytoscape-graph', 'tapNodeData'),\n",
    "    Input('cytoscape-graph', 'tapEdgeData')\n",
    ")\n",
    "def show_element_description(node_data, edge_data):\n",
    "    if not ctx.triggered:\n",
    "        return \"Click on a node or edge to see details.\"\n",
    "\n",
    "    triggered_prop = ctx.triggered[0][\"prop_id\"]\n",
    "\n",
    "    if triggered_prop == \"cytoscape-graph.tapNodeData\" and node_data:\n",
    "        return html.Div([\n",
    "            html.B(\"Node details:\"), html.Br(),\n",
    "            f\"Label: {node_data.get('fullLabel', node_data.get('label', ''))}\"\n",
    "        ])\n",
    "    elif triggered_prop == \"cytoscape-graph.tapEdgeData\" and edge_data:\n",
    "        return html.Div([\n",
    "            html.B(\"Edge details:\"), html.Br(),\n",
    "            f\"Subject: {edge_data.get('sub', edge_data.get('source', ''))}\", html.Br(),\n",
    "            f\"Relation(s): {edge_data.get('rel', edge_data.get('label', ''))}\", html.Br(),\n",
    "            f\"Object: {edge_data.get('obj', edge_data.get('target', ''))}\"\n",
    "        ])\n",
    "\n",
    "    return \"Click on a node or edge to see details.\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(mode='external', host='0.0.0.0', port=8070, debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0031949a-bd25-41ed-934b-3ae7ac5c3d50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KG Pipeline (GPU)",
   "language": "python",
   "name": "kg_pipeline"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
